{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e38e122-b9dd-499f-ac57-de0005ece87e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import boto3\n",
    "import json\n",
    "from minio import Minio\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.storage.queue import QueueClient\n",
    "from azure.storage.queue import TextBase64DecodePolicy\n",
    "from azure.storage.queue import TextBase64EncodePolicy\n",
    "\n",
    "\n",
    "# Create storage bucket client\n",
    "def create_storage_bucket_client(\n",
    "        bucket_name,\n",
    "        bucket_type=os.environ['STORAGE_TYPE'],\n",
    "        key1=os.environ['STORAGE_ACCESS_KEY'],\n",
    "        key2=os.environ['STORAGE_SECRET_KEY'],\n",
    "        endpoint=os.environ.get('STORAGE_ENDPOINT')):\n",
    "    if bucket_type == \"azure\":\n",
    "        return AzureStorageBucket(bucket_name, key1, key2)\n",
    "\n",
    "    elif bucket_type == \"s3\" and not endpoint:\n",
    "        return S3StorageBucket(bucket_name, key1, key2, endpoint)\n",
    "\n",
    "    elif bucket_type == \"s3\" and endpoint:\n",
    "        return MinioStorageBucket(bucket_name, key1, key2, endpoint)\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Bucket type not supported: \" + bucket_type)\n",
    "\n",
    "\n",
    "class StorageBucket():\n",
    "\n",
    "    def __init__(self, bucket_name, key1, key2):\n",
    "        self.bucket_name = bucket_name\n",
    "        self.key1 = key1\n",
    "        self.key2 = key2\n",
    "\n",
    "    def list_objects(self, file_path_prefix):\n",
    "        raise Exception(\"list_objects not implemented\")\n",
    "\n",
    "    def get_object_contents(self, file_path):\n",
    "        raise Exception(\"get_object_contents not implemented\")\n",
    "\n",
    "    def listen_changes(\n",
    "            self,\n",
    "            file_path_prefix,\n",
    "            file_path_suffix,\n",
    "            func,\n",
    "            queue_name=None):\n",
    "        raise Exception(\"listen_changes not implemented\")\n",
    "\n",
    "\n",
    "class AzureStorageBucket(StorageBucket):\n",
    "\n",
    "    def __init__(self, bucket_name, key1, key2):\n",
    "        super().__init__(bucket_name, key1, key2)\n",
    "        self.connect_str = (\n",
    "            \"DefaultEndpointsProtocol=https;AccountName=\" +\n",
    "            key1 +\n",
    "            \";AccountKey=\" +\n",
    "            key2 +\n",
    "            \";EndpointSuffix=core.windows.net\"\n",
    "        )\n",
    "        self.blob_service = BlobServiceClient.from_connection_string(\n",
    "            self.connect_str\n",
    "        )\n",
    "        self.container_client = self.blob_service.get_container_client(\n",
    "            bucket_name\n",
    "        )\n",
    "\n",
    "    def list_objects(self, file_path_prefix):\n",
    "        objects = []\n",
    "        blob_list = self.container_client.list_blobs(\n",
    "            name_starts_with=file_path_prefix\n",
    "        )\n",
    "        for blob in blob_list:\n",
    "            objects.append(blob.name)\n",
    "        return objects\n",
    "\n",
    "    def get_object_contents(self, file_path):\n",
    "        blob_client = self.container_client.get_blob_client(file_path)\n",
    "        bytes = blob_client.download_blob().readall()\n",
    "        if bytes is not None:\n",
    "            return io.BytesIO(bytes)\n",
    "        return None\n",
    "\n",
    "    def listen_changes(\n",
    "            self,\n",
    "            file_path_prefix,\n",
    "            file_path_suffix,\n",
    "            func,\n",
    "            queue_name=None):\n",
    "\n",
    "        queue_client = QueueClient.from_connection_string(\n",
    "            self.connect_str,\n",
    "            queue_name or self.bucket_name,\n",
    "            message_encode_policy=TextBase64EncodePolicy(),\n",
    "            message_decode_policy=TextBase64DecodePolicy()\n",
    "        )\n",
    "        # TODO: implement without continuous poll loop\n",
    "        while True:\n",
    "            messages = queue_client.receive_messages()\n",
    "            for message in messages:\n",
    "                url = None\n",
    "                try:\n",
    "                    content = json.loads(message.content)\n",
    "                    url = content['data']['url']\n",
    "                    url_split = content['data']['url'].split('/')\n",
    "                    file_path = '/'.join(url_split[4:])\n",
    "                    if (\n",
    "                            not file_path_prefix or\n",
    "                            file_path.startswith(file_path_prefix)\n",
    "                        ) and (\n",
    "                            not file_path_suffix or\n",
    "                            file_path.endswith(file_path_suffix)\n",
    "                            ):\n",
    "                        func(file_path)\n",
    "                    queue_client.delete_message(\n",
    "                        message.id,\n",
    "                        message.pop_receipt\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(\n",
    "                        \"ERROR: Failed to handle storage message for \" + url,\n",
    "                        file=sys.stderr\n",
    "                    )\n",
    "                    print(e, file=sys.stderr)\n",
    "            time.sleep(20)\n",
    "\n",
    "\n",
    "class S3StorageBucket(StorageBucket):\n",
    "\n",
    "    def __init__(self, bucket_name, key1, key2, endpoint=None):\n",
    "        super().__init__(bucket_name, key1, key2)\n",
    "        self.endpoint = endpoint\n",
    "\n",
    "        if not endpoint:\n",
    "            self.client = boto3.client(\n",
    "                's3',\n",
    "                aws_access_key_id=key1,\n",
    "                aws_secret_access_key=key2\n",
    "            )\n",
    "        else:\n",
    "            self.client = boto3.client(\n",
    "                's3',\n",
    "                aws_access_key_id=key1,\n",
    "                aws_secret_access_key=key2,\n",
    "                endpoint_url=\"http://\" + endpoint,\n",
    "                use_ssl=False\n",
    "            )\n",
    "\n",
    "    def list_objects(self, file_path_prefix):\n",
    "        objects = []\n",
    "        response = self.client.list_objects(\n",
    "            Bucket=self.bucket_name,\n",
    "            Prefix=file_path_prefix\n",
    "        )\n",
    "        if response is not None:\n",
    "            for obj in response['Contents']:\n",
    "                objects.append(obj['Key'])\n",
    "        return objects\n",
    "\n",
    "    def get_object_contents(self, file_path):\n",
    "        obj = self.client.get_object(Bucket=self.bucket_name, Key=file_path)\n",
    "        if obj is not None:\n",
    "            return obj['Body']\n",
    "        return None\n",
    "\n",
    "    def listen_changes(\n",
    "            self,\n",
    "            file_path_prefix,\n",
    "            file_path_suffix,\n",
    "            func,\n",
    "            queue_name=None):\n",
    "        raise Exception(\"listen_changes not implemented\")\n",
    "\n",
    "\n",
    "class MinioStorageBucket(S3StorageBucket):\n",
    "\n",
    "    def __init__(self, bucket_name, key1, key2, endpoint):\n",
    "        super().__init__(bucket_name, key1, key2, endpoint)\n",
    "\n",
    "    def listen_changes(\n",
    "            self,\n",
    "            file_path_prefix,\n",
    "            file_path_suffix,\n",
    "            func,\n",
    "            queue_name=None):\n",
    "        minio_client = Minio(\n",
    "            endpoint=self.endpoint,\n",
    "            access_key=self.key1,\n",
    "            secret_key=self.key2,\n",
    "            secure=False\n",
    "        )\n",
    "        events = minio_client.listen_bucket_notification(\n",
    "            self.bucket_name,\n",
    "            prefix=file_path_prefix,\n",
    "            suffix=file_path_suffix,\n",
    "            events=[\"s3:ObjectCreated:*\"]\n",
    "        )\n",
    "        for event in events:\n",
    "            file_path = ''\n",
    "            try:\n",
    "                file_path = event['Records'][0]['s3']['object']['key']\n",
    "                func(file_path)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    \"ERROR: Failed to handle storage event for \" + file_path,\n",
    "                    file=sys.stderr\n",
    "                )\n",
    "                print(e, file=sys.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c41aafe-7b5d-4cb8-98b2-7abcc1dceb6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
