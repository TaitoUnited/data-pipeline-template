{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6608c589-5455-45d2-a8eb-92b0dd033d77",
   "metadata": {},
   "source": [
    "# Basics 8: Create a new Power BI push dataset\n",
    "\n",
    "Unfortunately Power BI Service does not support PostgreSQL database as an online data source. PostgreSQL connection requires a separate Power BI Gateway installed on a Windows server. However, we can go around this limitation by creating a Power BI push dataset and pushing data from our data pipeline directly to Power BI Service.\n",
    "\n",
    "## Step 1: Create the Power BI push dataset\n",
    "\n",
    "Execute the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5166f1db-4f87-4166-890f-c28f82f9f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Load generic helper functions\n",
    "%run ../../common/jupyter.ipynb\n",
    "import src_common_database as db\n",
    "import src_common_powerbi as bi\n",
    "\n",
    "# Define database connection\n",
    "database = db.create_engine()\n",
    "\n",
    "# Define database tables that we need to replicate in Power BI\n",
    "tables = ['dim_dates', 'dim_products', 'dim_stores', 'fact_sales']\n",
    "\n",
    "# Read Power BI group id (workspace id) from an environment variable\n",
    "group_id = os.environ['POWERBI_GROUP_ID']\n",
    "\n",
    "# Create Power BI dataset schema based on our existing database tables\n",
    "dataset_schema = {\n",
    "    \"name\": \"Sales\",\n",
    "    \"defaultMode\": \"Push\",\n",
    "    \"tables\": list(map(lambda table : bi.as_powerbi_table_schema(table, database), tables)),\n",
    "    # Foreign key references of the fact_sales table\n",
    "    \"relationships\": [\n",
    "        {\n",
    "            \"name\": \"Sale date\",\n",
    "            \"fromTable\": \"public fact_sales\",\n",
    "            \"fromColumn\": \"date_key\",\n",
    "            \"toTable\": \"public dim_dates\",\n",
    "            \"toColumn\": \"key\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Sale store\",\n",
    "            \"fromTable\": \"public fact_sales\",\n",
    "            \"fromColumn\": \"store_key\",\n",
    "            \"toTable\": \"public dim_stores\",\n",
    "            \"toColumn\": \"key\"\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"name\": \"Sale product\",\n",
    "            \"fromTable\": \"public fact_sales\",\n",
    "            \"fromColumn\": \"product_key\",\n",
    "            \"toTable\": \"public dim_products\",\n",
    "            \"toColumn\": \"key\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# OPTIONAL: Add additional definitions like dataCategory and summarizeBy for columns, etc. See:\n",
    "# https://docs.microsoft.com/en-us/power-bi/developer/automation/api-dataset-properties\n",
    "\n",
    "# DEBUG: Print the schema\n",
    "print(json.dumps(dataset_schema, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ec850-0a04-4564-8222-46e99723ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get access token for accessing Power BI API\n",
    "app = bi.get_app()\n",
    "api_headers = bi.get_api_headers(app)\n",
    "\n",
    "# Create a new Power BI Push dataset based on the schema\n",
    "dataset_id = bi.create_dataset(api_headers, group_id, dataset_schema)\n",
    "\n",
    "# Print dataset id so that we can use it later\n",
    "print(\"dataset_id: \" + dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bad6723-91ca-4277-9efe-9b3f05135b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all data from our database to the Power BI dataset\n",
    "dataset = bi.PowerBIDataset(api_headers, group_id, dataset_id, table_name_prefix=\"public \")\n",
    "for table in tables:\n",
    "    dataset.copy_table_data(table_name=table, order_by='key', database=database)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ad0eff-7f04-412c-a00a-3533edc7be8a",
   "metadata": {},
   "source": [
    "> WARNING: If your dataset contains over 1 million rows, you cannot push all of them at once within one hour.\n",
    "> See [Power BI REST API limitations](https://docs.microsoft.com/en-us/power-bi/developer/automation/api-rest-api-limitations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bced70f2-336b-4a36-b43e-8a692d79ec19",
   "metadata": {},
   "source": [
    "## Step 2: Configure dataset id as an environment variable\n",
    "\n",
    "We configure the dataset id as an environment variable so that our data pipeline can push data to the dataset:\n",
    "\n",
    "1. Configure **dataset id** in **docker-compose.yaml** for local development:\n",
    "\n",
    "```yaml\n",
    "  data-pipeline-template-worker:\n",
    "    environment:\n",
    "      POWERBI_DATASET_ID: 2a240645-4c88-454d-a54c-3f1c91f4a25f\n",
    "      \n",
    "  data-pipeline-template-lab:\n",
    "    environment:\n",
    "      POWERBI_DATASET_ID: 2a240645-4c88-454d-a54c-3f1c91f4a25f\n",
    "```\n",
    "\n",
    "2. Optional: Configure **dataset id** in `scripts/helm.yaml` for Kubernetes:\n",
    "\n",
    "```yaml\n",
    "    worker:\n",
    "      env:\n",
    "        POWERBI_DATASET_ID: 2a240645-4c88-454d-a54c-3f1c91f4a25f\n",
    "```\n",
    "\n",
    "3. Stop containers with **ctrl-c** and then start them again with `taito start`. This is required for configuration changes to take effect.\n",
    "\n",
    "TIP: You can find more instructions on environment variables in [Taito CLI documentation](https://taitounited.github.io/taito-cli/tutorial/06-env-variables-and-secrets/).\n",
    "\n",
    "## Step 3: Republish the Power BI report with the new Power BI dataset\n",
    "\n",
    "1. Open your report in **Power BI Desktop**.\n",
    "2. Save the report with a new name by selecting **File -> Save As**.\n",
    "3. Select **Transform data -> Transform data**.\n",
    "4. Select all queries from the left pane (keep shift key down and click each of them).\n",
    "5. Delete selected queries by clicking right mouse button and selecting **Delete**.\n",
    "6. Close the view with by selecting **Close & apply**.\n",
    "7. Select **Power BI datasets**.\n",
    "8. Select your Power BI push dataset from the list of datasets.\n",
    "9. Save your report with **File -> Save**.\n",
    "10. Publish your report by selecting **File -> Publish**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cd5304-7d50-4cbb-aba9-5760546ea62c",
   "metadata": {},
   "source": [
    "## Next lesson: [Basics 9: Keep Power BI dataset up-to-date](09.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82fd91-2313-4b85-b115-fc5eab8904ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
