{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb3063a-feaa-4a77-952f-3b2aa48cea7c",
   "metadata": {},
   "source": [
    "# Basics 10: Real implementation and project configuration\n",
    "\n",
    "So far you have executed all code within Jupyter Lab. In this lesson we modify the real implementation located at the **server/src** folder.\n",
    "\n",
    "## Step 1: Review the example implementation\n",
    "\n",
    "1. Open the files **server/execute** and **server/src/example/services/sale_etl_service.py** in your code editor to see their contents.\n",
    "\n",
    "2. Execute the implementation inside the server container by running `taito exec:server ./execute sales_run`.\n",
    "\n",
    "## Step 2: Review the ways to execute your implementation\n",
    "\n",
    "There are multiple ways to execute your implementation:\n",
    "\n",
    "1. **Webhook:** Trigger your implementation based on an incoming http request. See **server/src/example/routers/action_router.py** as an example. You can trigger it with browser with `/api/example/actions/extract_sales?api_key=secret1234`. Note that in real use it is recommended to use **POST** instead of **GET** and to provide api key with X-API-KEY request header instead of **api_key** query parameter.\n",
    "\n",
    "2. **Continuous:** Start your implementation in **server/src/worker.py** as a separate thread, and it will run continuously. Use the **sale_etl_service.listen** as an example. This is good for listening events, for example storage bucket uploads.\n",
    "\n",
    "3. **Scheduled:** Add a cron job schedule in **scripts/helm.yaml**. This is good for task that need to be run periodically, for example every night or once a week. Note that cron jobs are run on Kubernetes only. You can find more info on cron job scheduling at https://en.wikipedia.org/wiki/Cron and https://crontab.guru. Example:\n",
    "\n",
    "```yaml\n",
    "    worker:\n",
    "      ...\n",
    "      cronJobs:\n",
    "        - name: sales-run\n",
    "          schedule: \"0 2 * * *\"\n",
    "          concurrencyPolicy: Forbid # Forbid or Allow next cron job to start before the previous has stopped\n",
    "          args:\n",
    "            - ./execute\n",
    "            - sales_run\n",
    "```\n",
    "\n",
    "4. **Manual:** Execute implementation manually with `taito exec:server:ENV ./execute COMMAND`. This is good for tasks that only need to be run occasionally, for example creating a new Power BI push dataset or refreshing an existing Power BI dataset schema. You can also use this for retrying automatic operations that have failed.\n",
    "\n",
    "5. **Custom Taito CLI command:** You can make a [custom Taito CLI command](https://taitounited.github.io/taito-cli/docs/09-custom-commands) that runs the `taito exec:server:ENV ./execute COMMAND` command for you. For example `taito powerbi refresh`. This makes it easier to execute manual operations that need to be executed often.\n",
    "\n",
    "## Step 3: Add your own implementation\n",
    "\n",
    "Now that you know all the basics, you should create your own implemention at the **server/src** folder and make it work on the local environment first. For example:\n",
    "\n",
    "1. Stop the containers, checkout another Git branch that does not include the changes you made during the lessons, and start containers again with `taito start --clean`.\n",
    "2. Add some dimension tables and one fact table to your database. This was explained in [lesson 3](03.ipynb).\n",
    "3. Add an implementation that updates dimension table data by reading CSV files located in a storage bucket. This was explained in lessons [1](01.ipynb) and [2](02.ipynb).\n",
    "4. Add an implementation that updates the fact table data by reading CSV files located in a storage bucket. This was explained in lessons [1](01.ipynb) and [2](02.ipynb).\n",
    "5. Trigger the aforementioned implementations either by continuous, scheduled, or manual execution. This was explained in [lesson 10](10.ipynb).\n",
    "6. Optional: If you use Apache Superset for visualizations, create a dataset view and dashboard on Apache Superset. This was explained in lessons [4](04.ipynb) and [5](05.ipynb).\n",
    "7. Optional: If you use Power BI Service for visualizations, add implemention for Power BI visualizations and integration as was explained in lessons [7](07.ipynb), [8](08.ipynb), and [9](09.ipynb). Make a custom Taito CLI commands for creating and refreshing the Power BI dataset as was explained in [lesson 10](10.ipynb).\n",
    "\n",
    "## Step 4: Create cloud environments\n",
    "\n",
    "Create development and production environments according to the **scripts/taito/CONFIGURATION.md** instructions, unless somebody has already done that.\n",
    "\n",
    "You can find additional instructions in markdown files located at **scripts/taito**. **CONFIGURATION.md** contains instructions for configuring your project, creating remote cloud environments, adding containers, adding storage buckets, setting user permissions, etc. **DEVELOPMENT.md** contains the most important Taito CLI commands that you should know and some additional development instructions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e5ad43-566f-422f-a84a-f24b913afc5e",
   "metadata": {},
   "source": [
    "## [Back to contents](../Contents.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b12ac0-b4cb-4fd1-814c-8994d51bbd70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
