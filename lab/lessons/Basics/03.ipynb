{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb3063a-feaa-4a77-952f-3b2aa48cea7c",
   "metadata": {},
   "source": [
    "# Basics 3: Add a new dimension table to database and create data pipeline for it\n",
    "\n",
    "In this lesson we add a new dimension table to our data model. The new **dim_stores** dimension describes the store where the sale was made. It also contains location information like postal code, region, city, and country. We could model location as a separate dimension, as it would be more reusable that way, but this time we choose to include location attributes directly in the **dim_stores** dimension.\n",
    "\n",
    "## Step 1: Add a new database migration\n",
    "\n",
    "1. Execute `taito db add dim_stores`.\n",
    "2. Add the following content to the newly created files (**database/deploy/dim_stores.sql**, **database/revert/dim_stores.sql**, and **database/verify/dim_stores.sql**).\n",
    "\n",
    "```sql\n",
    "-- Deploy dim_stores to pg\n",
    "\n",
    "BEGIN;\n",
    "\n",
    "CREATE TABLE dim_stores (\n",
    "  key text PRIMARY KEY,\n",
    "  name text NOT NULL,\n",
    "  postal_code text NOT NULL,\n",
    "  city text NOT NULL,\n",
    "  country text NOT NULL\n",
    ");\n",
    "\n",
    "CREATE VIEW load_stores AS SELECT * FROM dim_stores;\n",
    "\n",
    "CREATE OR REPLACE FUNCTION load_stores() RETURNS TRIGGER AS $$\n",
    "BEGIN\n",
    "  INSERT INTO dim_stores VALUES (NEW.*)\n",
    "  ON CONFLICT (key) DO\n",
    "    UPDATE SET\n",
    "      name = EXCLUDED.name,\n",
    "      postal_code = EXCLUDED.postal_code,\n",
    "      city = EXCLUDED.city,\n",
    "      country = EXCLUDED.country;\n",
    "  RETURN new;\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;\n",
    "\n",
    "CREATE TRIGGER load_stores\n",
    "INSTEAD OF INSERT ON load_stores\n",
    "FOR EACH ROW EXECUTE PROCEDURE load_stores();\n",
    "\n",
    "COMMIT;\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- Revert dim_stores from pg\n",
    "\n",
    "BEGIN;\n",
    "\n",
    "DROP TRIGGER load_stores ON load_stores;\n",
    "DROP FUNCTION load_stores;\n",
    "DROP VIEW load_stores;\n",
    "DROP TABLE dim_stores;\n",
    "\n",
    "COMMIT;\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- Verify dim_stores on pg\n",
    "\n",
    "BEGIN;\n",
    "\n",
    "SELECT key FROM load_stores LIMIT 1;\n",
    "SELECT key FROM dim_stores LIMIT 1;\n",
    "\n",
    "ROLLBACK;\n",
    "```\n",
    "\n",
    "3. Deploy the new database migration to local database with `taito db deploy`.\n",
    "\n",
    "## Step 2: Create a CSV files for districts and stores, and upload them to bucket\n",
    "\n",
    "1. Create district.csv file with the following content:\n",
    "\n",
    "```excel\n",
    "Postal Code,City,Country\n",
    "Unknown,Unknown,Unknown\n",
    "00100,Helsinki,Finland\n",
    "11122,Stockholm,Sweden\n",
    "```\n",
    "\n",
    "2. Create stores.csv file with the following content:\n",
    "\n",
    "```excel\n",
    "Name,Postal Code\n",
    "Unknown,Unknown\n",
    "Super Shop,00100\n",
    "Super Shop,11122\n",
    "```\n",
    "\n",
    "2. Upload both files to the root folder of the bucket\n",
    "\n",
    "## Step 3: Load the CSV file to database\n",
    "\n",
    "Execute the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "514e13da-c784-4935-9b10-7d20e63881e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceNotFoundError",
     "evalue": "The specified blob does not exist.\nRequestId:17a0323d-601e-0097-07ca-508124000000\nTime:2021-05-24T18:28:37.9969709Z\nErrorCode:BlobNotFound\nError:None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceNotFoundError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/azure/storage/blob/_download.py\u001b[0m in \u001b[0;36m_initial_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                 location_mode, response = self._clients.blob.download(\n\u001b[0m\u001b[1;32m    387\u001b[0m                     \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/azure/storage/blob/_generated/operations/_blob_operations.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, snapshot, version_id, timeout, range, range_get_content_md5, range_get_content_crc64, request_id_parameter, lease_access_conditions, cpk_info, modified_access_conditions, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m206\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mmap_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStorageError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/azure/core/exceptions.py\u001b[0m in \u001b[0;36mmap_error\u001b[0;34m(status_code, response, error_map)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceNotFoundError\u001b[0m: Operation returned an invalid status 'The specified blob does not exist.'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceNotFoundError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6a57c8a9ef38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Read CSV files from the storage bucket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mbucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_storage_bucket_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'STORAGE_BUCKET'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdistricts_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbucket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_object_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/districts.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mstores_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbucket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_object_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/stores.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ef43451582a1>\u001b[0m in \u001b[0;36mget_object_contents\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_object_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mblob_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_blob_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblob_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_blob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbytes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/azure/core/tracing/decorator.py\u001b[0m in \u001b[0;36mwrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mspan_impl_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracing_implementation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspan_impl_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;31m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/azure/storage/blob/_blob_client.py\u001b[0m in \u001b[0;36mdownload_blob\u001b[0;34m(self, offset, length, **kwargs)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             **kwargs)\n\u001b[0;32m--> 828\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mStorageStreamDownloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     def _quick_query_options(self, query_expression,\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/azure/storage/blob/_download.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, clients, config, start_range, end_range, validate_content, encryption_options, max_concurrency, name, container, encoding, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m         )\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/azure/storage/blob/_download.py\u001b[0m in \u001b[0;36m_initial_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m                     \u001b[0mprocess_storage_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/azure/storage/blob/_shared/response_handlers.py\u001b[0m in \u001b[0;36mprocess_storage_error\u001b[0;34m(storage_error)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madditional_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madditional_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/azure/core/exceptions.py\u001b[0m in \u001b[0;36mraise_with_traceback\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAzureError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_traceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/azure/storage/blob/_download.py\u001b[0m in \u001b[0;36m_initial_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mretry_active\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                 location_mode, response = self._clients.blob.download(\n\u001b[0m\u001b[1;32m    387\u001b[0m                     \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                     \u001b[0mrange_get_content_md5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/azure/storage/blob/_generated/operations/_blob_operations.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, snapshot, version_id, timeout, range, range_get_content_md5, range_get_content_crc64, request_id_parameter, lease_access_conditions, cpk_info, modified_access_conditions, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m206\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mmap_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStorageError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/azure/core/exceptions.py\u001b[0m in \u001b[0;36mmap_error\u001b[0;34m(status_code, response, error_map)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceNotFoundError\u001b[0m: The specified blob does not exist.\nRequestId:17a0323d-601e-0097-07ca-508124000000\nTime:2021-05-24T18:28:37.9969709Z\nErrorCode:BlobNotFound\nError:None"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "# Load generic helper functions\n",
    "%run ../../common/jupyter.ipynb\n",
    "import src_common_database as db\n",
    "import src_common_storage as st\n",
    "import src_common_util as util\n",
    "\n",
    "# Read CSV files from the storage bucket\n",
    "bucket = st.create_storage_bucket_client(os.environ['STORAGE_BUCKET'])\n",
    "districts_csv = bucket.get_object_contents(\"/districts.csv\")\n",
    "stores_csv = bucket.get_object_contents(\"/stores.csv\")\n",
    "\n",
    "# Read CSV data into a Pandas dataframe\n",
    "districts_df = pd.read_csv(districts_csv)\n",
    "stores_df = pd.read_csv(stores_csv)\n",
    "\n",
    "# Merge\n",
    "df = pd.merge(stores_df, districts_df, on=['Postal Code','Postal Code'])\n",
    "\n",
    "# Change dataframe schema to match the database table\n",
    "db_df = df.rename(\n",
    "    columns = {\n",
    "        'Name': 'name',\n",
    "        'Postal Code': 'postal_code',\n",
    "        'City': 'city',\n",
    "        'Country': 'country',\n",
    "    },\n",
    "    inplace = False\n",
    ")\n",
    "\n",
    "# Generate unique key by concatenating concatenating name and country\n",
    "db_df[\"key\"] = db_df[\"country\"] + \" - \" + db_df[\"name\"]\n",
    "\n",
    "# Write the data to the \"load_stores\" view\n",
    "database = db.create_engine()\n",
    "db_df.to_sql('load_stores', con=database, if_exists='append', index=False)\n",
    "\n",
    "# DEBUG: Show the data stored in fact_sales. You manual data changes should have been overwritten.\n",
    "pd.read_sql('select * from dim_stores', con=database).style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f7098-77bf-4175-b649-5fe813a8bb82",
   "metadata": {},
   "source": [
    "## Step 4: Add dim_store reference to the fact_sales table\n",
    "\n",
    "This time you cannot just add the new columns to the existing fact_sales migration files, because fact_sales migration was created before the dim_sales migration. However, if you want to avoid creating a new migration just for one new column, you can do the following:\n",
    "\n",
    "1. Move the dim_stores migration one step up in **database/sqitch.plan** so that it will be executed before fact_sales.\n",
    "\n",
    "2. Add the new store_key column to the **database/deploy/fact_sales.sql** file:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE fact_sales (\n",
    "  ...\n",
    "  store_key text NOT NULL REFERENCES dim_stores (key),\n",
    "  ...\n",
    ");\n",
    "```\n",
    "\n",
    "3. Add at least one example store to the **database/data/dev.sql** file. Add the stores before the fact_sales.\n",
    "\n",
    "4. Add a store_key value for each example sale defined in **database/data/dev.sql**.\n",
    "\n",
    "5. Redeploy all database migrations and example data with `taito init --clean`. Redeploy is required because you altered the sqitch.plan order instead of creating a new ALTER TABLE database migration.\n",
    "\n",
    "## Step 5 (optional): Generate database documentation\n",
    "\n",
    "1. Generate database documentation with `taito db generate`.\n",
    "\n",
    "2. Open the `docs/database/index.html` file with your web browser. Note that your code editor may not display these files as they have been placed in .gitignore.\n",
    "\n",
    "3. Browse to **Relationships**.\n",
    "\n",
    "As you can see, our database model is based on [star schema](https://en.wikipedia.org/wiki/Star_schema).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7feca6-e692-4195-a1c1-b4418990f643",
   "metadata": {},
   "source": [
    "## Next lesson: [Basics 4 - Create a dataset view on top of star schema](04.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1afc5d-4516-4fd1-84c4-2bb90f579696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
